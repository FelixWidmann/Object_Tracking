{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS8HumAOzf-z",
        "outputId": "a77db0f5-f1e5-43f9-988b-1160c7ecce0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.234-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.234-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.234 ultralytics-thop-2.0.18\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Collecting filterpy\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from filterpy) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from filterpy) (1.16.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from filterpy) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->filterpy) (1.17.0)\n",
            "Building wheels for collected packages: filterpy\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110460 sha256=1109292e2fefac56acfd7f883c25cd41babb25548c0bdaf5c0e749c10359023a\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/bf/4c/b0c3f4798a0166668752312a67118b27a3cd341e13ac0ae6ee\n",
            "Successfully built filterpy\n",
            "Installing collected packages: filterpy\n",
            "Successfully installed filterpy-1.4.5\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy) (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "!pip install opencv-python\n",
        "!pip install filterpy\n",
        "!pip install scipy\n",
        "!pip install matplotlib\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install torch torchvision\n",
        "!pip install pillow\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from filterpy.kalman import KalmanFilter\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import os\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from IPython.display import clear_output\n",
        "from google.colab import drive\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "class KalmanBoxTracker:\n",
        "    \"\"\"\n",
        "    Represents the internal state of individual tracked objects using Kalman filter.\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "\n",
        "    def __init__(self, bbox):\n",
        "        \"\"\"\n",
        "        Initialize a tracker using initial bounding box.\n",
        "        bbox: [x1, y1, x2, y2, score]\n",
        "        \"\"\"\n",
        "        # Define constant velocity model\n",
        "        self.kf = KalmanFilter(dim_x=7, dim_z=4)\n",
        "\n",
        "        self.kf.F = np.array([\n",
        "            [1,0,0,0,1,0,0],\n",
        "            [0,1,0,0,0,1,0],\n",
        "            [0,0,1,0,0,0,1],\n",
        "            [0,0,0,1,0,0,0],\n",
        "            [0,0,0,0,1,0,0],\n",
        "            [0,0,0,0,0,1,0],\n",
        "            [0,0,0,0,0,0,1]\n",
        "        ])\n",
        "\n",
        "        self.kf.H = np.array([\n",
        "            [1,0,0,0,0,0,0],\n",
        "            [0,1,0,0,0,0,0],\n",
        "            [0,0,1,0,0,0,0],\n",
        "            [0,0,0,1,0,0,0]\n",
        "        ])\n",
        "\n",
        "        self.kf.R[2:,2:] *= 10.\n",
        "        self.kf.P[4:,4:] *= 1000.\n",
        "        self.kf.P *= 10.\n",
        "        self.kf.Q[-1,-1] *= 0.01\n",
        "        self.kf.Q[4:,4:] *= 0.01\n",
        "\n",
        "        self.kf.x[:4] = self.convert_bbox_to_z(bbox)\n",
        "\n",
        "        self.time_since_update = 0\n",
        "        self.id = KalmanBoxTracker.count\n",
        "        KalmanBoxTracker.count += 1\n",
        "        self.history = []\n",
        "        self.hits = 0\n",
        "        self.hit_streak = 0\n",
        "        self.age = 0\n",
        "\n",
        "        # Store confidence score\n",
        "        self.last_score = bbox[4] if len(bbox) > 4 else 0.0\n",
        "\n",
        "    def update(self, bbox):\n",
        "        \"\"\"Updates the state vector with observed bbox.\"\"\"\n",
        "        self.time_since_update = 0\n",
        "        self.history = []\n",
        "        self.hits += 1\n",
        "        self.hit_streak += 1\n",
        "        self.kf.update(self.convert_bbox_to_z(bbox))\n",
        "        self.last_score = bbox[4] if len(bbox) > 4 else 0.0\n",
        "\n",
        "    def predict(self):\n",
        "        \"\"\"Advances the state vector and returns predicted bounding box.\"\"\"\n",
        "        if (self.kf.x[6] + self.kf.x[2]) <= 0:\n",
        "            self.kf.x[6] *= 0.0\n",
        "        self.kf.predict()\n",
        "        self.age += 1\n",
        "        if self.time_since_update > 0:\n",
        "            self.hit_streak = 0\n",
        "        self.time_since_update += 1\n",
        "        self.history.append(self.convert_x_to_bbox(self.kf.x))\n",
        "        return self.history[-1]\n",
        "\n",
        "    def get_state(self):\n",
        "        \"\"\"Returns the current bounding box estimate.\"\"\"\n",
        "        return self.convert_x_to_bbox(self.kf.x)\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_bbox_to_z(bbox):\n",
        "        \"\"\"Convert [x1,y1,x2,y2] to [x,y,s,r]\"\"\"\n",
        "        w = bbox[2] - bbox[0]\n",
        "        h = bbox[3] - bbox[1]\n",
        "        x = bbox[0] + w/2.\n",
        "        y = bbox[1] + h/2.\n",
        "        s = w * h\n",
        "        r = w / float(h)\n",
        "        return np.array([x, y, s, r]).reshape((4, 1))\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_x_to_bbox(x, score=None):\n",
        "        \"\"\"Convert [x,y,s,r] to [x1,y1,x2,y2]\"\"\"\n",
        "        w = np.sqrt(x[2] * x[3])\n",
        "        h = x[2] / w\n",
        "        if score == None:\n",
        "            return np.array([x[0]-w/2., x[1]-h/2., x[0]+w/2., x[1]+h/2.]).reshape((1,4))\n",
        "        else:\n",
        "            return np.array([x[0]-w/2., x[1]-h/2., x[0]+w/2., x[1]+h/2., score]).reshape((1,5))\n",
        "\n",
        "class AppearanceExtractor:\n",
        "    \"\"\"\n",
        "    CNN-based appearance feature extractor for Deep SORT.\n",
        "    Uses pre-trained ResNet for feature extraction.\n",
        "    \"\"\"\n",
        "    def __init__(self, use_gpu=True):\n",
        "        self.device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"Appearance extractor using device: {self.device}\")\n",
        "\n",
        "        # Use ResNet18 as feature extractor\n",
        "        resnet = models.resnet18(pretrained=True)\n",
        "        self.model = nn.Sequential(*list(resnet.children())[:-1])\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "        self.feature_dim = 512\n",
        "\n",
        "        # Image preprocessing\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((128, 64)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def extract(self, frame, bbox):\n",
        "        \"\"\"\n",
        "        Extract appearance feature from bounding box region.\n",
        "        Returns L2-normalized feature vector.\n",
        "        \"\"\"\n",
        "        x1, y1, x2, y2 = [int(v) for v in bbox]\n",
        "\n",
        "        h, w = frame.shape[:2]\n",
        "        x1 = max(0, x1)\n",
        "        y1 = max(0, y1)\n",
        "        x2 = min(w, x2)\n",
        "        y2 = min(h, y2)\n",
        "\n",
        "        if x2 <= x1 or y2 <= y1:\n",
        "            return np.zeros(self.feature_dim)\n",
        "\n",
        "        crop = frame[y1:y2, x1:x2]\n",
        "\n",
        "        if crop.size == 0:\n",
        "            return np.zeros(self.feature_dim)\n",
        "\n",
        "        crop_rgb = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)\n",
        "        crop_pil = Image.fromarray(crop_rgb)\n",
        "\n",
        "        crop_tensor = self.transform(crop_pil).unsqueeze(0).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            features = self.model(crop_tensor)\n",
        "            features = features.squeeze()\n",
        "\n",
        "        features = features.cpu().numpy()\n",
        "        norm = np.linalg.norm(features)\n",
        "        if norm > 0:\n",
        "            features = features / norm\n",
        "\n",
        "        return features\n",
        "\n",
        "\n",
        "def cosine_distance(a, b):\n",
        "    \"\"\"Compute cosine distance between two feature vectors.\"\"\"\n",
        "    return 1.0 - np.dot(a, b)\n",
        "\n",
        "class DeepSORTTrack:\n",
        "    \"\"\"Single track for Deep SORT with appearance features.\"\"\"\n",
        "    def __init__(self, detection, track_id, feature):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            detection: [x1, y1, x2, y2, score]\n",
        "            track_id: unique ID\n",
        "            feature: appearance feature vector\n",
        "        \"\"\"\n",
        "        self.track_id = track_id\n",
        "        self.kalman = KalmanBoxTracker(detection)\n",
        "\n",
        "        # Appearance feature gallery (store last 100)\n",
        "        self.features = [feature]\n",
        "        self.max_features = 100\n",
        "\n",
        "        self.time_since_update = 0\n",
        "        self.hits = 1\n",
        "        self.age = 0\n",
        "\n",
        "    def predict(self):\n",
        "        \"\"\"Predict next position.\"\"\"\n",
        "        pred = self.kalman.predict()[0]\n",
        "        self.age += 1\n",
        "        if self.time_since_update > 0:\n",
        "            self.hits = 0\n",
        "        self.time_since_update += 1\n",
        "        return pred\n",
        "\n",
        "    def update(self, detection, feature):\n",
        "        \"\"\"Update with new detection and feature.\"\"\"\n",
        "        self.kalman.update(detection)\n",
        "\n",
        "        self.features.append(feature)\n",
        "        if len(self.features) > self.max_features:\n",
        "            self.features.pop(0)\n",
        "\n",
        "        self.hits += 1\n",
        "        self.time_since_update = 0\n",
        "\n",
        "    def get_state(self):\n",
        "        \"\"\"Get current bounding box.\"\"\"\n",
        "        return self.kalman.get_state()[0]\n",
        "\n",
        "    def get_score(self):\n",
        "        \"\"\"Get confidence score.\"\"\"\n",
        "        return self.kalman.last_score\n",
        "\n",
        "    def min_cost_feature(self, feature):\n",
        "        \"\"\"Compute minimum cosine distance to feature gallery.\"\"\"\n",
        "        if len(self.features) == 0:\n",
        "            return 1.0\n",
        "\n",
        "        distances = [cosine_distance(feature, f) for f in self.features]\n",
        "        return min(distances)\n",
        "\n",
        "class DeepSORT:\n",
        "    \"\"\"\n",
        "    Deep SORT: Simple Online Realtime Tracking with Deep Association Metric.\n",
        "    IMPROVED PARAMETERS FOR BETTER ID PERSISTENCE.\n",
        "    \"\"\"\n",
        "    def __init__(self, max_age=90, min_hits=1, iou_threshold=0.2, lambda_param=0.0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            max_age: Maximum frames to keep track without detection (increased to 90)\n",
        "            min_hits: Minimum hits to confirm track (decreased to 1)\n",
        "            iou_threshold: IOU threshold for matching (decreased to 0.2)\n",
        "            lambda_param: 0 = appearance only (paper recommendation)\n",
        "        \"\"\"\n",
        "        self.max_age = max_age\n",
        "        self.min_hits = min_hits\n",
        "        self.iou_threshold = iou_threshold\n",
        "        self.lambda_param = lambda_param\n",
        "\n",
        "        self.tracks = []\n",
        "        self.next_id = 1\n",
        "        self.frame_count = 0\n",
        "\n",
        "        print(\"Initializing Deep SORT appearance extractor...\")\n",
        "        self.appearance_extractor = AppearanceExtractor()\n",
        "        print(\"Deep SORT ready!\")\n",
        "\n",
        "    def update(self, detections, frame):\n",
        "        \"\"\"\n",
        "        Update tracker with new detections.\n",
        "\n",
        "        Args:\n",
        "            detections: numpy array (N, 5) - [x1, y1, x2, y2, conf]\n",
        "            frame: current frame (numpy array)\n",
        "\n",
        "        Returns:\n",
        "            tracks: numpy array (M, 6) - [x1, y1, x2, y2, track_id, score]\n",
        "        \"\"\"\n",
        "        self.frame_count += 1\n",
        "\n",
        "        # Step 1: Predict new locations\n",
        "        predicted_boxes = []\n",
        "        for track in self.tracks:\n",
        "            pred = track.predict()\n",
        "            predicted_boxes.append(pred)\n",
        "        predicted_boxes = np.array(predicted_boxes) if predicted_boxes else np.empty((0, 4))\n",
        "\n",
        "        # Step 2: Extract appearance features for detections\n",
        "        detection_features = []\n",
        "        for det in detections:\n",
        "            feature = self.appearance_extractor.extract(frame, det[:4])\n",
        "            detection_features.append(feature)\n",
        "\n",
        "        # Step 3: Compute cost matrix\n",
        "        if len(self.tracks) > 0 and len(detections) > 0:\n",
        "            cost_matrix = self._compute_cost_matrix(\n",
        "                predicted_boxes, detections, detection_features\n",
        "            )\n",
        "        else:\n",
        "            cost_matrix = np.empty((0, 0))\n",
        "\n",
        "        # Step 4: Hungarian assignment\n",
        "        if cost_matrix.size > 0:\n",
        "            row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
        "            matches = []\n",
        "            unmatched_detections = set(range(len(detections)))\n",
        "            unmatched_tracks = set(range(len(self.tracks)))\n",
        "\n",
        "            # Filter matches by cost threshold (more lenient)\n",
        "            for r, c in zip(row_ind, col_ind):\n",
        "                if cost_matrix[r, c] < 0.8:  # Increased from 0.7 to 0.8\n",
        "                    matches.append((r, c))\n",
        "                    unmatched_detections.discard(c)\n",
        "                    unmatched_tracks.discard(r)\n",
        "        else:\n",
        "            matches = []\n",
        "            unmatched_detections = set(range(len(detections)))\n",
        "            unmatched_tracks = set(range(len(self.tracks)))\n",
        "\n",
        "        # Step 5: Update matched tracks\n",
        "        for track_idx, det_idx in matches:\n",
        "            self.tracks[track_idx].update(\n",
        "                detections[det_idx],\n",
        "                detection_features[det_idx]\n",
        "            )\n",
        "\n",
        "        # Step 6: Create new tracks (lowered threshold)\n",
        "        for det_idx in unmatched_detections:\n",
        "            if detections[det_idx][4] >= 0.3:  # Lowered from 0.5 to 0.3\n",
        "                new_track = DeepSORTTrack(\n",
        "                    detections[det_idx],\n",
        "                    self.next_id,\n",
        "                    detection_features[det_idx]\n",
        "                )\n",
        "                self.tracks.append(new_track)\n",
        "                self.next_id += 1\n",
        "\n",
        "        # Step 7: Remove dead tracks\n",
        "        self.tracks = [t for t in self.tracks if t.time_since_update < self.max_age]\n",
        "\n",
        "        # Step 8: Return confirmed tracks\n",
        "        output_tracks = []\n",
        "        for track in self.tracks:\n",
        "            if track.hits >= self.min_hits or self.frame_count <= self.min_hits:\n",
        "                state = track.get_state()\n",
        "                score = track.get_score()\n",
        "                output_tracks.append(\n",
        "                    np.array([state[0], state[1], state[2], state[3], track.track_id, score])\n",
        "                )\n",
        "\n",
        "        if len(output_tracks) > 0:\n",
        "            return np.array(output_tracks)\n",
        "        return np.empty((0, 6))\n",
        "\n",
        "    def _compute_cost_matrix(self, predicted_boxes, detections, detection_features):\n",
        "        \"\"\"Compute combined motion + appearance cost matrix.\"\"\"\n",
        "        n_tracks = len(self.tracks)\n",
        "        n_detections = len(detections)\n",
        "        cost_matrix = np.zeros((n_tracks, n_detections))\n",
        "\n",
        "        for i, (track, pred_box) in enumerate(zip(self.tracks, predicted_boxes)):\n",
        "            for j, (det, det_feature) in enumerate(zip(detections, detection_features)):\n",
        "                # Motion cost (1 - IOU)\n",
        "                iou = self._compute_iou(pred_box, det[:4])\n",
        "                motion_cost = 1.0 - iou\n",
        "\n",
        "                # Appearance cost\n",
        "                appearance_cost = track.min_cost_feature(det_feature)\n",
        "\n",
        "                # Combined cost (lambda=0 means appearance only)\n",
        "                cost_matrix[i, j] = (\n",
        "                    self.lambda_param * motion_cost +\n",
        "                    (1 - self.lambda_param) * appearance_cost\n",
        "                )\n",
        "\n",
        "        return cost_matrix\n",
        "\n",
        "    @staticmethod\n",
        "    def _compute_iou(box1, box2):\n",
        "        \"\"\"Compute IOU between two boxes.\"\"\"\n",
        "        x1 = max(box1[0], box2[0])\n",
        "        y1 = max(box1[1], box2[1])\n",
        "        x2 = min(box1[2], box2[2])\n",
        "        y2 = min(box1[3], box2[3])\n",
        "\n",
        "        intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "        union = area1 + area2 - intersection\n",
        "\n",
        "        if union == 0:\n",
        "            return 0\n",
        "        return intersection / union\n",
        "\n",
        "class RobotDetector:\n",
        "    \"\"\"YOLO-based detector for FRC robots.\"\"\"\n",
        "    def __init__(self, model_name='best.pt', conf_threshold=0.05):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            model_name: Path to YOLO model\n",
        "            conf_threshold: Minimum confidence (lowered to 0.05)\n",
        "        \"\"\"\n",
        "        print(f\"Loading YOLO model: {model_name}\")\n",
        "        self.model = YOLO(model_name)\n",
        "        self.conf_threshold = conf_threshold\n",
        "        print(f\" Model loaded successfully!\")\n",
        "\n",
        "    def detect(self, frame):\n",
        "        \"\"\"\n",
        "        Detect robots in frame.\n",
        "        Returns: numpy array (N, 5) - [x1, y1, x2, y2, conf]\n",
        "        \"\"\"\n",
        "        results = self.model(frame, conf=self.conf_threshold, verbose=False)\n",
        "\n",
        "        detections = []\n",
        "        for result in results:\n",
        "            boxes = result.boxes\n",
        "            for box in boxes:\n",
        "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "                conf = box.conf[0].cpu().numpy()\n",
        "                cls = box.cls[0].cpu().numpy()\n",
        "\n",
        "                if cls == 0:  # Adjust based on your model\n",
        "                    detections.append([x1, y1, x2, y2, conf])\n",
        "\n",
        "        if len(detections) > 0:\n",
        "            return np.array(detections)\n",
        "        else:\n",
        "            return np.empty((0, 5))\n",
        "\n",
        "def draw_tracks_on_frame(frame, tracks):\n",
        "    \"\"\"Draw bounding boxes and IDs on frame.\"\"\"\n",
        "    frame_copy = frame.copy()\n",
        "    np.random.seed(42)\n",
        "    colors = np.random.randint(0, 255, size=(1000, 3), dtype=np.uint8)\n",
        "\n",
        "    for track in tracks:\n",
        "        x1, y1, x2, y2, track_id, score = track\n",
        "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "        track_id = int(track_id)\n",
        "\n",
        "        color = tuple(int(c) for c in colors[track_id % len(colors)])\n",
        "\n",
        "        cv2.rectangle(frame_copy, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "        label = f\"Robot {track_id} ({score:.2f})\"\n",
        "        label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
        "        cv2.rectangle(frame_copy, (x1, y1 - label_size[1] - 10),\n",
        "                     (x1 + label_size[0], y1), color, -1)\n",
        "        cv2.putText(frame_copy, label, (x1, y1 - 5),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "\n",
        "    return frame_copy\n",
        "\n",
        "def process_video_to_csv(video_path, output_csv_path, model_name='best.pt', display_every=100, save_frames=True, frames_output_folder=None):\n",
        "    \"\"\"\n",
        "    Process video with Deep SORT and save to CSV.\n",
        "\n",
        "    CSV format: video_name, frame, timestamp, track_id, x1, y1, x2, y2, score\n",
        "    \"\"\"\n",
        "    # Initialize detector and tracker\n",
        "    detector = RobotDetector(model_name=model_name, conf_threshold=0.05)\n",
        "    tracker = DeepSORT(max_age=90, min_hits=1, iou_threshold=0.2, lambda_param=0.0)\n",
        "\n",
        "    # Reset tracker count\n",
        "    KalmanBoxTracker.count = 0\n",
        "\n",
        "    # Create folder for sample frames\n",
        "    if save_frames:\n",
        "        if frames_output_folder is None:\n",
        "            frames_output_folder = Path(output_csv_path).parent / 'sample_frames'\n",
        "        frames_output_folder = Path(frames_output_folder)\n",
        "        frames_output_folder.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "        video_frames_folder = frames_output_folder / Path(video_path).stem\n",
        "        video_frames_folder.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    # Open video\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    print(f\"\\nProcessing: {Path(video_path).name}\")\n",
        "    print(f\"Resolution: {width}x{height} @ {fps:.2f} FPS\")\n",
        "    print(f\"Total frames: {total_frames}\")\n",
        "\n",
        "    frame_count = 0\n",
        "    tracking_data = []\n",
        "    frames_saved = 0\n",
        "    save_interval = max(total_frames // 10, 30)\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_count += 1\n",
        "        timestamp = frame_count / fps\n",
        "\n",
        "        # Detect robots\n",
        "        detections = detector.detect(frame)\n",
        "\n",
        "        # Update tracker (Deep SORT needs frame for appearance)\n",
        "        tracks = tracker.update(detections, frame)\n",
        "\n",
        "        # Save sample frames\n",
        "        if save_frames and (frame_count % save_interval == 0 or frame_count == 1) and len(tracks) > 0:\n",
        "            frame_with_tracks = draw_tracks_on_frame(frame, tracks)\n",
        "            frame_filename = video_frames_folder / f\"frame_{frame_count:05d}.jpg\"\n",
        "            cv2.imwrite(str(frame_filename), frame_with_tracks)\n",
        "            frames_saved += 1\n",
        "\n",
        "        # Store tracking data\n",
        "        for track in tracks:\n",
        "            x1, y1, x2, y2, track_id, score = track\n",
        "\n",
        "            tracking_data.append({\n",
        "                'video_name': Path(video_path).name,\n",
        "                'frame': frame_count,\n",
        "                'timestamp': timestamp,\n",
        "                'track_id': int(track_id),\n",
        "                'x1': x1,\n",
        "                'y1': y1,\n",
        "                'x2': x2,\n",
        "                'y2': y2,\n",
        "                'score': score\n",
        "            })\n",
        "\n",
        "        # Display progress\n",
        "        if frame_count % display_every == 0:\n",
        "            print(f\"Progress: {frame_count}/{total_frames} ({100*frame_count/total_frames:.1f}%) - Current tracks: {len(tracks)}\")\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(tracking_data)\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "    print(f\" Saved tracking data to: {output_csv_path}\")\n",
        "    print(f\"  Total detections: {len(df)}\")\n",
        "    if len(df) > 0:\n",
        "        print(f\"  Unique track IDs: {df['track_id'].nunique()}\")\n",
        "        print(f\"  Max track ID seen: {df['track_id'].max()}\")\n",
        "    if save_frames:\n",
        "        print(f\"  Sample frames saved: {frames_saved} in {video_frames_folder}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def process_folder_to_csv(data_folder, output_folder, model_name='best.pt', save_sample_frames=True):\n",
        "    \"\"\"Process all MP4 videos in folder with Deep SORT.\"\"\"\n",
        "    data_folder = Path(data_folder)\n",
        "    output_folder = Path(output_folder)\n",
        "    output_folder.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    video_files = list(data_folder.glob('*.mp4')) + list(data_folder.glob('*.MP4'))\n",
        "\n",
        "    print(f\"Found {len(video_files)} MP4 videos in {data_folder}\")\n",
        "\n",
        "    if len(video_files) == 0:\n",
        "        print(\" No MP4 files found.\")\n",
        "        return {}\n",
        "\n",
        "    all_results = {}\n",
        "    all_dataframes = []\n",
        "\n",
        "    for i, video_path in enumerate(video_files):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Video {i+1}/{len(video_files)}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        output_csv = output_folder / f\"{video_path.stem}_tracking.csv\"\n",
        "\n",
        "        try:\n",
        "            df = process_video_to_csv(\n",
        "                video_path,\n",
        "                output_csv,\n",
        "                model_name=model_name,\n",
        "                save_frames=save_sample_frames,\n",
        "                frames_output_folder=output_folder / 'sample_frames'\n",
        "            )\n",
        "            all_results[video_path.name] = df\n",
        "            all_dataframes.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\" Error processing {video_path.name}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "\n",
        "    # Create combined CSV\n",
        "    if all_dataframes:\n",
        "        combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
        "        combined_csv_path = output_folder / \"all_videos_combined.csv\"\n",
        "        combined_df.to_csv(combined_csv_path, index=False)\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\" Saved combined tracking data to: {combined_csv_path}\")\n",
        "        print(f\"  Total rows: {len(combined_df)}\")\n",
        "        print(f\"  Videos processed: {len(all_dataframes)}\")\n",
        "\n",
        "    # Summary\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"BATCH PROCESSING SUMMARY - Deep SORT\")\n",
        "    print(\"=\"*60)\n",
        "    for video_name, df in all_results.items():\n",
        "        if len(df) > 0:\n",
        "            print(f\"\\n{video_name}:\")\n",
        "            print(f\"  - Total detections: {len(df)}\")\n",
        "            print(f\"  - Unique track IDs: {df['track_id'].nunique()}\")\n",
        "            print(f\"  - Max track ID: {df['track_id'].max()}\")\n",
        "            print(f\"  - Duration: {df['timestamp'].max():.2f}s\")\n",
        "            print(f\"  - Avg detections/frame: {len(df)/df['frame'].max():.2f}\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "DATA_FOLDER = '/content/drive/MyDrive/Colab Notebooks/Test'\n",
        "OUTPUT_FOLDER = '/content/drive/MyDrive/Colab Notebooks/DeepSORTTesting'\n",
        "MODEL_PATH = '/content/drive/MyDrive/Colab Notebooks/best.pt'\n",
        "\n",
        "# print(\"DEEP SORT WITH IMPROVED SETTINGS:\")\n",
        "# print(\"  - max_age: 90 frames - keeps tracks alive longer during occlusion\")\n",
        "# print(\"  - min_hits: 1 - confirms tracks immediately\")\n",
        "# print(\"  - iou_threshold: 0.2 - more lenient matching\")\n",
        "# print(\"  - lambda: 0.0 - appearance-based matching (paper recommendation)\")\n",
        "# print(\"  - YOLO conf: 0.05 - detects more robots\")\n",
        "# print(\"  - Appearance model: ResNet18 pre-trained features\")\n",
        "\n",
        "# Process all videos\n",
        "results = process_folder_to_csv(\n",
        "    data_folder=DATA_FOLDER,\n",
        "    output_folder=OUTPUT_FOLDER,\n",
        "    model_name=MODEL_PATH,\n",
        "    save_sample_frames=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QW_Aw3X5w7IP",
        "outputId": "2c578804-5181-401c-b632-280e9486b349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Found 1 MP4 videos in /content/drive/MyDrive/Colab Notebooks/Test\n",
            "\n",
            "============================================================\n",
            "Video 1/1\n",
            "============================================================\n",
            "Loading YOLO model: /content/drive/MyDrive/Colab Notebooks/best.pt\n",
            " Model loaded successfully!\n",
            "Initializing Deep SORT appearance extractor...\n",
            "Appearance extractor using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 66.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep SORT ready!\n",
            "\n",
            "Processing: test.mp4\n",
            "Resolution: 1920x1080 @ 29.99 FPS\n",
            "Total frames: 4766\n",
            "Progress: 100/4766 (2.1%) - Current tracks: 11\n",
            "Progress: 200/4766 (4.2%) - Current tracks: 15\n",
            "Progress: 300/4766 (6.3%) - Current tracks: 13\n",
            "Progress: 400/4766 (8.4%) - Current tracks: 12\n",
            "Progress: 500/4766 (10.5%) - Current tracks: 9\n",
            "Progress: 600/4766 (12.6%) - Current tracks: 9\n",
            "Progress: 700/4766 (14.7%) - Current tracks: 9\n",
            "Progress: 800/4766 (16.8%) - Current tracks: 8\n",
            "Progress: 900/4766 (18.9%) - Current tracks: 11\n",
            "Progress: 1000/4766 (21.0%) - Current tracks: 16\n",
            "Progress: 1100/4766 (23.1%) - Current tracks: 13\n",
            "Progress: 1200/4766 (25.2%) - Current tracks: 11\n",
            "Progress: 1300/4766 (27.3%) - Current tracks: 18\n",
            "Progress: 1400/4766 (29.4%) - Current tracks: 10\n",
            "Progress: 1500/4766 (31.5%) - Current tracks: 12\n",
            "Progress: 1600/4766 (33.6%) - Current tracks: 18\n",
            "Progress: 1700/4766 (35.7%) - Current tracks: 18\n",
            "Progress: 1800/4766 (37.8%) - Current tracks: 9\n",
            "Progress: 1900/4766 (39.9%) - Current tracks: 14\n",
            "Progress: 2000/4766 (42.0%) - Current tracks: 14\n",
            "Progress: 2100/4766 (44.1%) - Current tracks: 11\n",
            "Progress: 2200/4766 (46.2%) - Current tracks: 18\n",
            "Progress: 2300/4766 (48.3%) - Current tracks: 10\n",
            "Progress: 2400/4766 (50.4%) - Current tracks: 13\n",
            "Progress: 2500/4766 (52.5%) - Current tracks: 15\n",
            "Progress: 2600/4766 (54.6%) - Current tracks: 11\n",
            "Progress: 2700/4766 (56.7%) - Current tracks: 9\n",
            "Progress: 2800/4766 (58.7%) - Current tracks: 14\n",
            "Progress: 2900/4766 (60.8%) - Current tracks: 15\n",
            "Progress: 3000/4766 (62.9%) - Current tracks: 14\n",
            "Progress: 3100/4766 (65.0%) - Current tracks: 12\n",
            "Progress: 3200/4766 (67.1%) - Current tracks: 12\n",
            "Progress: 3300/4766 (69.2%) - Current tracks: 14\n",
            "Progress: 3400/4766 (71.3%) - Current tracks: 18\n",
            "Progress: 3500/4766 (73.4%) - Current tracks: 12\n",
            "Progress: 3600/4766 (75.5%) - Current tracks: 9\n",
            "Progress: 3700/4766 (77.6%) - Current tracks: 13\n",
            "Progress: 3800/4766 (79.7%) - Current tracks: 16\n",
            "Progress: 3900/4766 (81.8%) - Current tracks: 10\n",
            "Progress: 4000/4766 (83.9%) - Current tracks: 13\n",
            "Progress: 4100/4766 (86.0%) - Current tracks: 19\n",
            "Progress: 4200/4766 (88.1%) - Current tracks: 19\n",
            "Progress: 4300/4766 (90.2%) - Current tracks: 19\n",
            "Progress: 4400/4766 (92.3%) - Current tracks: 20\n",
            "Progress: 4500/4766 (94.4%) - Current tracks: 16\n",
            "Progress: 4600/4766 (96.5%) - Current tracks: 17\n",
            "Progress: 4700/4766 (98.6%) - Current tracks: 10\n",
            " Saved tracking data to: /content/drive/MyDrive/Colab Notebooks/DeepSORTTesting/test_tracking.csv\n",
            "  Total detections: 62321\n",
            "  Unique track IDs: 32\n",
            "  Max track ID seen: 32\n",
            "  Sample frames saved: 11 in /content/drive/MyDrive/Colab Notebooks/DeepSORTTesting/sample_frames/test\n",
            "\n",
            "============================================================\n",
            " Saved combined tracking data to: /content/drive/MyDrive/Colab Notebooks/DeepSORTTesting/all_videos_combined.csv\n",
            "  Total rows: 62321\n",
            "  Videos processed: 1\n",
            "\n",
            "============================================================\n",
            "BATCH PROCESSING SUMMARY - Deep SORT\n",
            "============================================================\n",
            "\n",
            "test.mp4:\n",
            "  - Total detections: 62321\n",
            "  - Unique track IDs: 32\n",
            "  - Max track ID: 32\n",
            "  - Duration: 158.90s\n",
            "  - Avg detections/frame: 13.08\n"
          ]
        }
      ]
    }
  ]
}