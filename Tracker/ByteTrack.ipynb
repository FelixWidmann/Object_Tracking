{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF9_BNXLpvf1",
        "outputId": "68347fd9-c4eb-442a-9e2b-eb183044acc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.234-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.234-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.234 ultralytics-thop-2.0.18\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Collecting filterpy\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from filterpy) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from filterpy) (1.16.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from filterpy) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->filterpy) (1.17.0)\n",
            "Building wheels for collected packages: filterpy\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110460 sha256=fadd13b98ec3f4e4a8ad9ce8ca23b76e638b5be0c4ba7cebee5ed27fdd6b737d\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/bf/4c/b0c3f4798a0166668752312a67118b27a3cd341e13ac0ae6ee\n",
            "Successfully built filterpy\n",
            "Installing collected packages: filterpy\n",
            "Successfully installed filterpy-1.4.5\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy) (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics  # YOLO\n",
        "!pip install opencv-python\n",
        "!pip install filterpy  # Kalman filter\n",
        "!pip install scipy  # Hungarian algorithm\n",
        "!pip install matplotlib\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from filterpy.kalman import KalmanFilter\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import os\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from IPython.display import clear_output\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNca1rrmqft-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1adeab6e-d6e7-4c4c-844c-2ab2af663192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 1 MP4 videos in /content/drive/MyDrive/Colab Notebooks/Test\n",
            "\n",
            "============================================================\n",
            "Video 1/1\n",
            "============================================================\n",
            "\n",
            "Processing: test.mp4\n",
            "Resolution: 1920x1080 @ 29.99 FPS\n",
            "Total frames: 4766\n",
            "Progress: 100/4766 (2.1%) - Current tracks: 3\n",
            "Progress: 200/4766 (4.2%) - Current tracks: 4\n",
            "Progress: 300/4766 (6.3%) - Current tracks: 6\n",
            "Progress: 400/4766 (8.4%) - Current tracks: 5\n",
            "Progress: 500/4766 (10.5%) - Current tracks: 5\n",
            "Progress: 600/4766 (12.6%) - Current tracks: 5\n",
            "Progress: 700/4766 (14.7%) - Current tracks: 4\n",
            "Progress: 800/4766 (16.8%) - Current tracks: 4\n",
            "Progress: 900/4766 (18.9%) - Current tracks: 6\n",
            "Progress: 1000/4766 (21.0%) - Current tracks: 5\n",
            "Progress: 1100/4766 (23.1%) - Current tracks: 3\n",
            "Progress: 1200/4766 (25.2%) - Current tracks: 4\n",
            "Progress: 1300/4766 (27.3%) - Current tracks: 4\n",
            "Progress: 1400/4766 (29.4%) - Current tracks: 4\n",
            "Progress: 1500/4766 (31.5%) - Current tracks: 2\n",
            "Progress: 1600/4766 (33.6%) - Current tracks: 6\n",
            "Progress: 1700/4766 (35.7%) - Current tracks: 6\n",
            "Progress: 1800/4766 (37.8%) - Current tracks: 6\n",
            "Progress: 1900/4766 (39.9%) - Current tracks: 4\n",
            "Progress: 2000/4766 (42.0%) - Current tracks: 5\n",
            "Progress: 2100/4766 (44.1%) - Current tracks: 5\n",
            "Progress: 2200/4766 (46.2%) - Current tracks: 5\n",
            "Progress: 2300/4766 (48.3%) - Current tracks: 2\n",
            "Progress: 2400/4766 (50.4%) - Current tracks: 5\n",
            "Progress: 2500/4766 (52.5%) - Current tracks: 6\n",
            "Progress: 2600/4766 (54.6%) - Current tracks: 5\n",
            "Progress: 2700/4766 (56.7%) - Current tracks: 4\n",
            "Progress: 2800/4766 (58.7%) - Current tracks: 6\n",
            "Progress: 2900/4766 (60.8%) - Current tracks: 4\n",
            "Progress: 3000/4766 (62.9%) - Current tracks: 4\n",
            "Progress: 3100/4766 (65.0%) - Current tracks: 5\n",
            "Progress: 3200/4766 (67.1%) - Current tracks: 5\n",
            "Progress: 3300/4766 (69.2%) - Current tracks: 5\n",
            "Progress: 3400/4766 (71.3%) - Current tracks: 6\n",
            "Progress: 3500/4766 (73.4%) - Current tracks: 4\n",
            "Progress: 3600/4766 (75.5%) - Current tracks: 4\n",
            "Progress: 3700/4766 (77.6%) - Current tracks: 6\n",
            "Progress: 3800/4766 (79.7%) - Current tracks: 7\n",
            "Progress: 3900/4766 (81.8%) - Current tracks: 4\n",
            "Progress: 4000/4766 (83.9%) - Current tracks: 5\n",
            "Progress: 4100/4766 (86.0%) - Current tracks: 5\n",
            "Progress: 4200/4766 (88.1%) - Current tracks: 4\n",
            "Progress: 4300/4766 (90.2%) - Current tracks: 7\n",
            "Progress: 4400/4766 (92.3%) - Current tracks: 7\n",
            "Progress: 4500/4766 (94.4%) - Current tracks: 6\n",
            "Progress: 4600/4766 (96.5%) - Current tracks: 7\n",
            "Progress: 4700/4766 (98.6%) - Current tracks: 6\n",
            " Saved tracking data to: /content/drive/MyDrive/Colab Notebooks/ByteTrack_Testing/test_tracking.csv\n",
            "  Total detections: 24049\n",
            "  Unique track IDs: 119\n",
            "  Max track ID seen: 119\n",
            "  Sample frames saved: 11 in /content/drive/MyDrive/Colab Notebooks/ByteTrack_Testing/sample_frames/test\n",
            "\n",
            "============================================================\n",
            " Saved combined tracking data to: /content/drive/MyDrive/Colab Notebooks/ByteTrack_Testing/all_videos_combined.csv\n",
            "  Total rows: 24049\n",
            "  Videos processed: 1\n",
            "\n",
            "============================================================\n",
            "BATCH PROCESSING SUMMARY - OPTIMIZED ID PERSISTENCE\n",
            "============================================================\n",
            "\n",
            "test.mp4:\n",
            "  - Total detections: 24049\n",
            "  - Unique track IDs: 119\n",
            "  - Max track ID: 119\n",
            "  - Duration: 158.90s\n",
            "  - Avg detections/frame: 5.05\n",
            "\n",
            "============================================================\n",
            "Sample data from test.mp4:\n",
            "============================================================\n",
            "  video_name  frame  timestamp  track_id           x1          y1  \\\n",
            "0   test.mp4      1   0.033340         2   383.067749  642.394258   \n",
            "1   test.mp4      1   0.033340         1  1468.304138  586.498138   \n",
            "2   test.mp4      2   0.066681         2   382.584601  640.715515   \n",
            "3   test.mp4      2   0.066681         1  1468.232528  586.469860   \n",
            "4   test.mp4      3   0.100021         2   382.526991  640.591432   \n",
            "5   test.mp4      3   0.100021         1  1468.258247  587.176849   \n",
            "6   test.mp4      4   0.133361         2   382.229546  640.009955   \n",
            "7   test.mp4      4   0.133361         1  1468.378674  587.952633   \n",
            "8   test.mp4      5   0.166702         2   382.224170  640.290986   \n",
            "9   test.mp4      5   0.166702         1  1468.482148  587.666969   \n",
            "\n",
            "            x2          y2     score  \n",
            "0   445.297241  737.033965  0.707508  \n",
            "1  1565.888733  689.998200  0.732883  \n",
            "2   445.414459  737.058576  0.706707  \n",
            "3  1565.834867  689.901734  0.731740  \n",
            "4   445.413090  737.118722  0.706754  \n",
            "5  1565.766981  690.321110  0.727217  \n",
            "6   445.427665  737.104188  0.706581  \n",
            "7  1565.612598  690.438123  0.749146  \n",
            "8   445.454276  737.256596  0.703570  \n",
            "9  1565.637568  690.035767  0.718103  \n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from filterpy.kalman import KalmanFilter\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "class KalmanBoxTracker:\n",
        "    \"\"\"\n",
        "    This class represents the internal state of individual tracked objects observed as bbox.\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "\n",
        "    def __init__(self, bbox):\n",
        "        \"\"\"\n",
        "        Initialises a tracker using initial bounding box.\n",
        "        bbox: [x1, y1, x2, y2, score]\n",
        "        \"\"\"\n",
        "        # Define constant velocity model\n",
        "        # State: [cx, cy, s, r, v_cx, v_cy, v_s] (center_x, center_y, scale, aspect_ratio, and their velocities)\n",
        "        self.kf = KalmanFilter(dim_x=7, dim_z=4)\n",
        "\n",
        "        # State Transition Matrix F (Constant Velocity Model)\n",
        "        self.kf.F = np.array([\n",
        "            [1,0,0,0,1,0,0],\n",
        "            [0,1,0,0,0,1,0],\n",
        "            [0,0,1,0,0,0,1],\n",
        "            [0,0,0,1,0,0,0],\n",
        "            [0,0,0,0,1,0,0],\n",
        "            [0,0,0,0,0,1,0],\n",
        "            [0,0,0,0,0,0,1]\n",
        "        ])\n",
        "\n",
        "        # Measurement Function H (Measures [cx, cy, s, r] from the state)\n",
        "        self.kf.H = np.array([\n",
        "            [1,0,0,0,0,0,0],\n",
        "            [0,1,0,0,0,0,0],\n",
        "            [0,0,1,0,0,0,0],\n",
        "            [0,0,0,1,0,0,0]\n",
        "        ])\n",
        "\n",
        "        # Measurement Noise Covariance R\n",
        "        # MODIFIED: Reduced R scaling from 10. to 5. to trust detection size/ratio slightly more.\n",
        "        self.kf.R[2:,2:] *= 5.0\n",
        "\n",
        "        # Initial State Covariance P (Uncertainty)\n",
        "        self.kf.P[4:,4:] *= 1000.\n",
        "        self.kf.P *= 10.\n",
        "\n",
        "        # Process Noise Covariance Q (Trust in the motion model)\n",
        "        # MODIFIED: Increased Q[4:,4:] multiplier from 0.01 to 0.5\n",
        "        # to allow the velocity states (v_cx, v_cy, v_s) to change more quickly,\n",
        "        # better tracking fast robot movements.\n",
        "        self.kf.Q[-1,-1] *= 0.01\n",
        "        self.kf.Q[4:,4:] *= 0.5  # MODIFIED: Increased from 0.01 to 0.5\n",
        "\n",
        "        self.kf.x[:4] = self.convert_bbox_to_z(bbox)\n",
        "        self.time_since_update = 0\n",
        "        self.id = KalmanBoxTracker.count\n",
        "        KalmanBoxTracker.count += 1\n",
        "        self.history = []\n",
        "        self.hits = 0\n",
        "        self.hit_streak = 0\n",
        "        self.age = 0\n",
        "\n",
        "        # Store confidence score\n",
        "        self.last_score = bbox[4] if len(bbox) > 4 else 0.0\n",
        "\n",
        "    def update(self, bbox):\n",
        "        \"\"\"\n",
        "        Updates the state vector with observed bbox.\n",
        "        \"\"\"\n",
        "        self.time_since_update = 0\n",
        "        self.history = []\n",
        "        self.hits += 1\n",
        "        self.hit_streak += 1\n",
        "        self.kf.update(self.convert_bbox_to_z(bbox))\n",
        "\n",
        "        # Update confidence score\n",
        "        self.last_score = bbox[4] if len(bbox) > 4 else 0.0\n",
        "\n",
        "    def predict(self):\n",
        "        \"\"\"\n",
        "        Advances the state vector and returns the predicted bounding box estimate.\n",
        "        \"\"\"\n",
        "        if (self.kf.x[6] + self.kf.x[2]) <= 0:\n",
        "            self.kf.x[6] *= 0.0\n",
        "        self.kf.predict()\n",
        "        self.age += 1\n",
        "        if self.time_since_update > 0:\n",
        "            self.hit_streak = 0\n",
        "        self.time_since_update += 1\n",
        "        self.history.append(self.convert_x_to_bbox(self.kf.x))\n",
        "        return self.history[-1]\n",
        "\n",
        "    def get_state(self):\n",
        "        \"\"\"\n",
        "        Returns the current bounding box estimate.\n",
        "        \"\"\"\n",
        "        return self.convert_x_to_bbox(self.kf.x)\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_bbox_to_z(bbox):\n",
        "        \"\"\"\n",
        "        Takes a bounding box in the form [x1,y1,x2,y2] and returns z in the form\n",
        "        [x,y,s,r] where x,y is the centre of the box and s is the scale/area and r is\n",
        "        the aspect ratio\n",
        "        \"\"\"\n",
        "        w = bbox[2] - bbox[0]\n",
        "        h = bbox[3] - bbox[1]\n",
        "        x = bbox[0] + w/2.\n",
        "        y = bbox[1] + h/2.\n",
        "        s = w * h\n",
        "        r = w / float(h)\n",
        "        return np.array([x, y, s, r]).reshape((4, 1))\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_x_to_bbox(x, score=None):\n",
        "        \"\"\"\n",
        "        Takes a bounding box in the centre form [x,y,s,r] and returns it in the form\n",
        "        [x1,y1,x2,y2] where x1,y1 is the top left and x2,y2 is the bottom right\n",
        "        \"\"\"\n",
        "        w = np.sqrt(x[2] * x[3])\n",
        "        h = x[2] / w\n",
        "        if score == None:\n",
        "            return np.array([x[0]-w/2., x[1]-h/2., x[0]+w/2., x[1]+h/2.]).reshape((1,4))\n",
        "        else:\n",
        "            return np.array([x[0]-w/2., x[1]-h/2., x[0]+w/2., x[1]+h/2., score]).reshape((1,5))\n",
        "\n",
        "def iou_batch(bb_test, bb_gt):\n",
        "    \"\"\"\n",
        "    Computes IOU between two bboxes in the form [x1,y1,x2,y2]\n",
        "    \"\"\"\n",
        "    bb_gt = np.expand_dims(bb_gt, 0)\n",
        "    bb_test = np.expand_dims(bb_test, 1)\n",
        "\n",
        "    xx1 = np.maximum(bb_test[..., 0], bb_gt[..., 0])\n",
        "    yy1 = np.maximum(bb_test[..., 1], bb_gt[..., 1])\n",
        "    xx2 = np.minimum(bb_test[..., 2], bb_gt[..., 2])\n",
        "    yy2 = np.minimum(bb_test[..., 3], bb_gt[..., 3])\n",
        "    w = np.maximum(0., xx2 - xx1)\n",
        "    h = np.maximum(0., yy2 - yy1)\n",
        "    wh = w * h\n",
        "    o = wh / ((bb_test[..., 2] - bb_test[..., 0]) * (bb_test[..., 3] - bb_test[..., 1])\n",
        "        + (bb_gt[..., 2] - bb_gt[..., 0]) * (bb_gt[..., 3] - bb_gt[..., 1]) - wh)\n",
        "    return(o)\n",
        "\n",
        "\n",
        "def associate_detections_to_trackers(detections, trackers, iou_threshold=0.3):\n",
        "    \"\"\"\n",
        "    Assigns detections to tracked object (both represented as bounding boxes)\n",
        "    Returns 3 lists of matches, unmatched_detections and unmatched_trackers\n",
        "    \"\"\"\n",
        "    if len(trackers) == 0:\n",
        "        return np.empty((0, 2), dtype=int), np.arange(len(detections)), np.empty((0, 5), dtype=int)\n",
        "\n",
        "    iou_matrix = iou_batch(detections, trackers)\n",
        "\n",
        "    if min(iou_matrix.shape) > 0:\n",
        "        a = (iou_matrix > iou_threshold).astype(np.int32)\n",
        "        if a.sum(1).max() == 1 and a.sum(0).max() == 1:\n",
        "            matched_indices = np.stack(np.where(a), axis=1)\n",
        "        else:\n",
        "            # Use Hungarian algorithm for optimal assignment\n",
        "            matched_indices = linear_sum_assignment(-iou_matrix)\n",
        "            matched_indices = np.array(list(zip(*matched_indices)))\n",
        "    else:\n",
        "        matched_indices = np.empty(shape=(0, 2))\n",
        "\n",
        "    unmatched_detections = []\n",
        "    for d, det in enumerate(detections):\n",
        "        if d not in matched_indices[:, 0]:\n",
        "            unmatched_detections.append(d)\n",
        "    unmatched_trackers = []\n",
        "    for t, trk in enumerate(trackers):\n",
        "        if t not in matched_indices[:, 1]:\n",
        "            unmatched_trackers.append(t)\n",
        "\n",
        "    matches = []\n",
        "    for m in matched_indices:\n",
        "        if iou_matrix[m[0], m[1]] < iou_threshold:\n",
        "            unmatched_detections.append(m[0])\n",
        "            unmatched_trackers.append(m[1])\n",
        "        else:\n",
        "            matches.append(m.reshape(1, 2))\n",
        "\n",
        "    if len(matches) == 0:\n",
        "        matches = np.empty((0, 2), dtype=int)\n",
        "    else:\n",
        "        matches = np.concatenate(matches, axis=0)\n",
        "\n",
        "    return matches, np.array(unmatched_detections), np.array(unmatched_trackers)\n",
        "\n",
        "class ByteTrack:\n",
        "    \"\"\"\n",
        "    ByteTrack: Multi-Object Tracking by Associating Every Detection Box\n",
        "    Uses two-stage association with high and low confidence detections\n",
        "    \"\"\"\n",
        "    def __init__(self, max_age=90, min_hits=1, iou_threshold=0.2):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            max_age: Maximum frames to keep track alive without detection (90 frames)\n",
        "            min_hits: Minimum detections before track confirmed (1 hit)\n",
        "            iou_threshold: Minimum IOU for match (0.2)\n",
        "        \"\"\"\n",
        "        self.max_age = max_age\n",
        "        self.min_hits = min_hits\n",
        "        self.iou_threshold = iou_threshold\n",
        "        self.trackers = []\n",
        "        self.frame_count = 0\n",
        "\n",
        "        # ByteTrack confidence thresholds\n",
        "        # MODIFIED: high_thresh increased from 0.5 to 0.7\n",
        "        # to ensure primary association uses very confident detections, reducing ID switch.\n",
        "        self.high_thresh = 0.7  # MODIFIED: Increased from 0.5\n",
        "        self.low_thresh = 0.05  # Kept at 0.05\n",
        "\n",
        "    def update(self, detections):\n",
        "        \"\"\"\n",
        "        Params:\n",
        "          detections - a numpy array of detections in the format [[x1,y1,x2,y2,score],[x1,y1,x2,y2,score],...]\n",
        "        Returns:\n",
        "          a similar array, where the last column is the object ID and the second to last is score.\n",
        "        \"\"\"\n",
        "        self.frame_count += 1\n",
        "\n",
        "        trks = np.zeros((len(self.trackers), 5))\n",
        "        to_del = []\n",
        "        ret = []\n",
        "        for t, trk in enumerate(trks):\n",
        "            pos = self.trackers[t].predict()[0]\n",
        "            trk[:] = [pos[0], pos[1], pos[2], pos[3], 0]\n",
        "            if np.any(np.isnan(pos)):\n",
        "                to_del.append(t)\n",
        "        trks = np.ma.compress_rows(np.ma.masked_invalid(trks))\n",
        "        for t in reversed(to_del):\n",
        "            self.trackers.pop(t)\n",
        "\n",
        "        # ----------------- First Association (High Confidence Detections) -----------------\n",
        "        if len(detections) > 0:\n",
        "            high_detections = detections[detections[:, 4] >= self.high_thresh]\n",
        "            low_detections = detections[(detections[:, 4] >= self.low_thresh) &\n",
        "                                       (detections[:, 4] < self.high_thresh)]\n",
        "        else:\n",
        "            high_detections = np.empty((0, 5))\n",
        "            low_detections = np.empty((0, 5))\n",
        "\n",
        "        matched, unmatched_dets, unmatched_trks = associate_detections_to_trackers(\n",
        "            high_detections, trks, self.iou_threshold\n",
        "        )\n",
        "\n",
        "        for m in matched:\n",
        "            self.trackers[int(m[1])].update(high_detections[int(m[0]), :])\n",
        "\n",
        "        # Tracks that were not matched to high-confidence detections\n",
        "        unmatched_trks_first_stage = unmatched_trks.astype(int)\n",
        "\n",
        "        # ----------------- Second Association (Low Confidence Detections) -----------------\n",
        "        if len(low_detections) > 0 and len(unmatched_trks_first_stage) > 0:\n",
        "            unmatched_trks_boxes = trks[unmatched_trks_first_stage]\n",
        "\n",
        "            matched_low, unmatched_dets_low, unmatched_trks_low = associate_detections_to_trackers(\n",
        "                low_detections, unmatched_trks_boxes, self.iou_threshold\n",
        "            )\n",
        "\n",
        "            for m in matched_low:\n",
        "                tracker_idx = int(unmatched_trks_first_stage[int(m[1])])\n",
        "                self.trackers[tracker_idx].update(low_detections[int(m[0]), :])\n",
        "\n",
        "            # Unmatched trackers from both stages\n",
        "            unmatched_trks = unmatched_trks_first_stage[unmatched_trks_low.astype(int)]\n",
        "\n",
        "        # ----------------- Initialise New Tracks -----------------\n",
        "        unmatched_dets = unmatched_dets.astype(int)\n",
        "        for i in unmatched_dets:\n",
        "            # Only use unmatched high-confidence detections to create new tracks\n",
        "            if i < len(high_detections):\n",
        "                trk = KalmanBoxTracker(high_detections[i, :])\n",
        "                self.trackers.append(trk)\n",
        "\n",
        "        # ----------------- Output and Delete Tracks -----------------\n",
        "        i = len(self.trackers)\n",
        "        for trk in reversed(self.trackers):\n",
        "            d = trk.get_state()[0]\n",
        "            if (trk.time_since_update < 1) and (trk.hit_streak >= self.min_hits or self.frame_count <= self.min_hits):\n",
        "                # Return [x1, y1, x2, y2, track_id, score]\n",
        "                ret.append(np.concatenate((d, [trk.id + 1, trk.last_score])).reshape(1, -1))\n",
        "            i -= 1\n",
        "            # Delete tracks that haven't been updated for max_age frames\n",
        "            if trk.time_since_update > self.max_age:\n",
        "                self.trackers.pop(i)\n",
        "\n",
        "        if len(ret) > 0:\n",
        "            return np.concatenate(ret)\n",
        "        return np.empty((0, 6))\n",
        "\n",
        "class RobotDetector:\n",
        "    \"\"\"\n",
        "    YOLO-based detector for FRC robots\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name='best.pt', conf_threshold=0.05):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            model_name: YOLO model to use\n",
        "            conf_threshold: Minimum confidence for detections\n",
        "        \"\"\"\n",
        "        self.model = YOLO(model_name)\n",
        "        # MODIFIED: Increased YOLO conf_threshold from 0.05 to 0.1\n",
        "        # to reduce noisy initial detections, minimizing false track creation.\n",
        "        self.conf_threshold = 0.1 # MODIFIED: Increased from 0.05\n",
        "\n",
        "    def detect(self, frame):\n",
        "        \"\"\"\n",
        "        Detect robots in frame\n",
        "\n",
        "        Args:\n",
        "            frame: numpy array (H, W, 3)\n",
        "\n",
        "        Returns:\n",
        "            detections: numpy array of shape (N, 5) where each row is [x1, y1, x2, y2, conf]\n",
        "        \"\"\"\n",
        "        # Pass the (now higher) self.conf_threshold to the YOLO model\n",
        "        results = self.model(frame, conf=self.conf_threshold, verbose=False)\n",
        "\n",
        "        detections = []\n",
        "        for result in results:\n",
        "            boxes = result.boxes\n",
        "            for box in boxes:\n",
        "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "                conf = box.conf[0].cpu().numpy()\n",
        "                cls = box.cls[0].cpu().numpy()\n",
        "\n",
        "                # Adjust class filter as needed for your YOLO model\n",
        "                if cls == 0:  # Assuming 0 is the robot class\n",
        "                    detections.append([x1, y1, x2, y2, conf])\n",
        "\n",
        "        if len(detections) > 0:\n",
        "            return np.array(detections)\n",
        "        else:\n",
        "            return np.empty((0, 5))\n",
        "\n",
        "def draw_tracks_on_frame(frame, tracks):\n",
        "    \"\"\"\n",
        "    Draw bounding boxes and IDs on frame\n",
        "    \"\"\"\n",
        "    frame_copy = frame.copy()\n",
        "    np.random.seed(42)\n",
        "    colors = np.random.randint(0, 255, size=(1000, 3), dtype=np.uint8)\n",
        "\n",
        "    for track in tracks:\n",
        "        x1, y1, x2, y2, track_id, score = track\n",
        "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "        track_id = int(track_id)\n",
        "\n",
        "        color = tuple(int(c) for c in colors[track_id % len(colors)])\n",
        "\n",
        "        cv2.rectangle(frame_copy, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "        label = f\"Robot {track_id} ({score:.2f})\"\n",
        "        label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
        "        cv2.rectangle(frame_copy, (x1, y1 - label_size[1] - 10),\n",
        "                      (x1 + label_size[0], y1), color, -1)\n",
        "        cv2.putText(frame_copy, label, (x1, y1 - 5),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "\n",
        "    return frame_copy\n",
        "\n",
        "def process_video_to_csv(video_path, output_csv_path, model_name='best.pt', display_every=100, save_frames=True, frames_output_folder=None):\n",
        "    \"\"\"\n",
        "    Process a single video with ByteTrack and save results to CSV\n",
        "    \"\"\"\n",
        "    # Detector and tracker initialized with MODIFIED parameters\n",
        "    detector = RobotDetector(model_name=model_name)\n",
        "    tracker = ByteTrack(max_age=90, min_hits=1, iou_threshold=0.2)\n",
        "\n",
        "    # Reset tracker count for each video\n",
        "    KalmanBoxTracker.count = 0\n",
        "\n",
        "    # Create folder for sample frames if needed\n",
        "    if save_frames:\n",
        "        if frames_output_folder is None:\n",
        "            frames_output_folder = Path(output_csv_path).parent / 'sample_frames'\n",
        "        frames_output_folder = Path(frames_output_folder)\n",
        "        frames_output_folder.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "        video_frames_folder = frames_output_folder / Path(video_path).stem\n",
        "        video_frames_folder.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    # Open video\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    print(f\"\\nProcessing: {Path(video_path).name}\")\n",
        "    print(f\"Resolution: {width}x{height} @ {fps:.2f} FPS\")\n",
        "    print(f\"Total frames: {total_frames}\")\n",
        "\n",
        "    frame_count = 0\n",
        "    tracking_data = []\n",
        "    frames_saved = 0\n",
        "    save_interval = max(total_frames // 10, 30)  # Save ~10 frames per video\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_count += 1\n",
        "        timestamp = frame_count / fps  # Time in seconds\n",
        "\n",
        "        # Detect robots\n",
        "        detections = detector.detect(frame)\n",
        "\n",
        "        # Update tracker\n",
        "        tracks = tracker.update(detections)\n",
        "\n",
        "        # Save sample frames with detections\n",
        "        if save_frames and (frame_count % save_interval == 0 or frame_count == 1) and len(tracks) > 0:\n",
        "            frame_with_tracks = draw_tracks_on_frame(frame, tracks)\n",
        "            frame_filename = video_frames_folder / f\"frame_{frame_count:05d}.jpg\"\n",
        "            cv2.imwrite(str(frame_filename), frame_with_tracks)\n",
        "            frames_saved += 1\n",
        "\n",
        "        # Store tracking data\n",
        "        for track in tracks:\n",
        "            x1, y1, x2, y2, track_id, score = track\n",
        "\n",
        "            tracking_data.append({\n",
        "                'video_name': Path(video_path).name,\n",
        "                'frame': frame_count,\n",
        "                'timestamp': timestamp,\n",
        "                'track_id': int(track_id),\n",
        "                'x1': x1,\n",
        "                'y1': y1,\n",
        "                'x2': x2,\n",
        "                'y2': y2,\n",
        "                'score': score\n",
        "            })\n",
        "\n",
        "        # Display progress\n",
        "        if frame_count % display_every == 0:\n",
        "            print(f\"Progress: {frame_count}/{total_frames} ({100*frame_count/total_frames:.1f}%) - Current tracks: {len(tracks)}\")\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(tracking_data)\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "    print(f\" Saved tracking data to: {output_csv_path}\")\n",
        "    print(f\"  Total detections: {len(df)}\")\n",
        "    if len(df) > 0:\n",
        "        print(f\"  Unique track IDs: {df['track_id'].nunique()}\")\n",
        "        print(f\"  Max track ID seen: {df['track_id'].max()}\")\n",
        "    if save_frames:\n",
        "        print(f\"  Sample frames saved: {frames_saved} in {video_frames_folder}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def process_folder_to_csv(data_folder, output_folder, model_name='best.pt', save_sample_frames=True):\n",
        "    \"\"\"\n",
        "    Process all MP4 videos in a folder and save tracking results to CSVs\n",
        "    \"\"\"\n",
        "    data_folder = Path(data_folder)\n",
        "    output_folder = Path(output_folder)\n",
        "    output_folder.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    # Find all MP4 files\n",
        "    video_files = list(data_folder.glob('*.mp4')) + list(data_folder.glob('*.MP4'))\n",
        "\n",
        "    print(f\"Found {len(video_files)} MP4 videos in {data_folder}\")\n",
        "\n",
        "    if len(video_files) == 0:\n",
        "        print(\" No MP4 files found. Please check the folder path.\")\n",
        "        return {}\n",
        "\n",
        "    all_results = {}\n",
        "    all_dataframes = []\n",
        "\n",
        "    for i, video_path in enumerate(video_files):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Video {i+1}/{len(video_files)}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # Set output CSV path\n",
        "        output_csv = output_folder / f\"{video_path.stem}_tracking.csv\"\n",
        "\n",
        "        # Process video\n",
        "        try:\n",
        "            df = process_video_to_csv(\n",
        "                video_path,\n",
        "                output_csv,\n",
        "                model_name=model_name,\n",
        "                save_frames=save_sample_frames,\n",
        "                frames_output_folder=output_folder / 'sample_frames'\n",
        "            )\n",
        "            all_results[video_path.name] = df\n",
        "            all_dataframes.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\" Error processing {video_path.name}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "\n",
        "    # Create combined CSV with all videos\n",
        "    if all_dataframes:\n",
        "        combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
        "        combined_csv_path = output_folder / \"all_videos_combined.csv\"\n",
        "        combined_df.to_csv(combined_csv_path, index=False)\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\" Saved combined tracking data to: {combined_csv_path}\")\n",
        "        print(f\"  Total rows: {len(combined_df)}\")\n",
        "        print(f\"  Videos processed: {len(all_dataframes)}\")\n",
        "\n",
        "    # Summary\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"BATCH PROCESSING SUMMARY - OPTIMIZED ID PERSISTENCE\")\n",
        "    print(\"=\"*60)\n",
        "    for video_name, df in all_results.items():\n",
        "        if len(df) > 0:\n",
        "            print(f\"\\n{video_name}:\")\n",
        "            print(f\"  - Total detections: {len(df)}\")\n",
        "            print(f\"  - Unique track IDs: {df['track_id'].nunique()}\")\n",
        "            print(f\"  - Max track ID: {df['track_id'].max()}\")\n",
        "            print(f\"  - Duration: {df['timestamp'].max():.2f}s\")\n",
        "            print(f\"  - Avg detections/frame: {len(df)/df['frame'].max():.2f}\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "# Set your paths\n",
        "DATA_FOLDER = '/content/drive/MyDrive/Colab Notebooks/Test'\n",
        "OUTPUT_FOLDER = '/content/drive/MyDrive/Colab Notebooks/ByteTrack_Testing'\n",
        "MODEL_PATH = '/content/drive/MyDrive/Colab Notebooks/best.pt'\n",
        "\n",
        "# print(\"BYTETRACK SETTINGS FOR OPTIMIZED ID PERSISTENCE:\")\n",
        "# print(\" - max_age: 90 (Keeps tracks alive longer during occlusion)\")\n",
        "# print(\" - min_hits: 1 (Confirms tracks immediately)\")\n",
        "# print(\" - iou_threshold: 0.2 (Lenient matching)\")\n",
        "# print(\"-\" * 30)\n",
        "# print(\"KALMAN FILTER (for fast robot movement):\")\n",
        "# print(\" - Q[4:,4:] multiplier: 0.5 (MODIFIED: Trust in velocity change is higher)\")\n",
        "# print(\" - R[2:,2:] multiplier: 5.0 (MODIFIED: Trust in detection size/ratio is higher)\")\n",
        "# print(\"-\" * 30)\n",
        "# print(\"DETECTION THRESHOLDS (for better initialization):\")\n",
        "# print(\" - ByteTrack high_thresh: 0.7 (MODIFIED: Primary association uses more confident detections)\")\n",
        "# print(\" - YOLO conf: 0.1 (MODIFIED: Only initialize new tracks from better detections)\")\n",
        "# print(\"-\" * 30)\n",
        "\n",
        "\n",
        "# Process all videos in the Data folder\n",
        "results = process_folder_to_csv(\n",
        "    data_folder=DATA_FOLDER,\n",
        "    output_folder=OUTPUT_FOLDER,\n",
        "    model_name=MODEL_PATH,\n",
        "    save_sample_frames=True\n",
        ")\n",
        "\n",
        "# Display sample results\n",
        "if results:\n",
        "    first_video = list(results.keys())[0]\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Sample data from {first_video}:\")\n",
        "    print(\"=\"*60)\n",
        "    print(results[first_video].head(10))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}